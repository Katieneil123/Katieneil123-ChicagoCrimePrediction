{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Crime Prediction Project - 05Model Development Strategy (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Random Seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Data Path\n",
    "DATA_DIR = \"data/\"\n",
    "PROCESSED_DIR = \"data/processed/\"\n",
    "FEATURES_DIR = \"data/features/\"\n",
    "MODELS_DIR = \"models/\"\n",
    "RESULTS_DIR = \"results/\"\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_feature_data(filename):\n",
    "    filepath = os.path.join(FEATURES_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        if filename.endswith('.csv'):\n",
    "            return pd.read_csv(filepath, parse_dates=['date'])\n",
    "        elif filename.endswith('.parquet'):\n",
    "            return pd.read_parquet(filepath)\n",
    "        elif filename.endswith('.pkl'):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {filename}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "\n",
    "# Save Model\n",
    "def save_model(model, model_name, info=None):\n",
    "\n",
    "    filepath = os.path.join(MODELS_DIR, f\"{model_name}.pkl\")\n",
    "\n",
    "    try:\n",
    "        if isinstance(model, nn.Module):\n",
    "            torch.save(model.state_dict(), os.path.join(MODELS_DIR, f\"{model_name}.pt\"))\n",
    "        else:\n",
    "            joblib.dump(model, filepath)\n",
    "        \n",
    "        print(f\"Model saved to {filepath}\")\n",
    "        \n",
    "        if info:\n",
    "            info_filepath = os.path.join(MODELS_DIR, f\"{model_name}_info.json\")\n",
    "            info_df = pd.DataFrame([info])\n",
    "            info_df.to_json(info_filepath, orient='records')\n",
    "            print(f\"Model info saved to {info_filepath}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "        return False\n",
    "\n",
    "# Save Evaluation Results\n",
    "def save_evaluation_results(results, model_name):\n",
    "    filepath = os.path.join(RESULTS_DIR, f\"{model_name}_evaluation.txt\")\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(f\"Evaluation Results for {model_name}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                f.write(f\"{key}:\\n\")\n",
    "                for k, v in value.items():\n",
    "                    f.write(f\"  {k}: {v}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "    print(f\"Evaluation results saved to {filepath}\")\n",
    "    \n",
    "#------ Prepare Datasets ------#\n",
    "\n",
    "def prepare_datasets(df, target_col, test_size=0.3, random_state=42, features_to_drop=None):\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    if target_col not in data.columns:\n",
    "        print(f\"Error: Target column '{target_col}' not found in the dataset\")\n",
    "        return None\n",
    "    \n",
    "    if features_to_drop:\n",
    "        for col in features_to_drop:\n",
    "            if col in data.columns and col != target_col:\n",
    "                data = data.drop(col, axis=1)\n",
    "    \n",
    "    # Target Variable\n",
    "    y = data[target_col]\n",
    "    X = data.drop(target_col, axis=1)\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "    \n",
    "    print(f\"Features: {len(X.columns)} total, {len(categorical_cols)} categorical, {len(numerical_cols)} numerical\")\n",
    "    \n",
    "    # Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y if len(np.unique(y)) < 50 else None\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Check Target Distribution\n",
    "    target_distribution = pd.Series(y_train).value_counts(normalize=True)\n",
    "    print(f\"Target distribution in training set:\")\n",
    "    for target, percentage in target_distribution.items():\n",
    "        print(f\"  {target}: {percentage:.2%}\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'categorical_cols': categorical_cols,\n",
    "        'numerical_cols': numerical_cols,\n",
    "        'target_col': target_col\n",
    "    }\n",
    "    \n",
    "# Handle Class Imbalance\n",
    "def handle_class_imbalance(X_train, y_train, method='smote', sampling_strategy='auto', random_state=42):\n",
    "\n",
    "    print(f\"Handling class imbalance using {method}...\")\n",
    "    \n",
    "    if method == 'smote':\n",
    "        smote = SMOTE(sampling_strategy=sampling_strategy, random_state=random_state)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "    elif method == 'undersampling':\n",
    "        under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=random_state)\n",
    "        X_resampled, y_resampled = under_sampler.fit_resample(X_train, y_train)\n",
    "        \n",
    "    elif method == 'both':\n",
    "        over_sampler = SMOTE(sampling_strategy=sampling_strategy, random_state=random_state)\n",
    "        under_sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=random_state)\n",
    "        \n",
    "\n",
    "        X_over, y_over = over_sampler.fit_resample(X_train, y_train)\n",
    "        X_resampled, y_resampled = under_sampler.fit_resample(X_over, y_over)\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid method. Using original data.\")\n",
    "        return X_train, y_train\n",
    "    \n",
    "    # Calculate Class Distribution\n",
    "    resampled_dist = pd.Series(y_resampled).value_counts(normalize=True)\n",
    "    print(\"Class distribution after resampling:\")\n",
    "    for cls, pct in resampled_dist.items():\n",
    "        print(f\"  {cls}: {pct:.2%}\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Create Preprocessing Pipeline\n",
    "def create_preprocessing_pipeline(categorical_cols, numerical_cols):\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  \n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numerical', numerical_pipeline, numerical_cols),\n",
    "        ('categorical', categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def get_data_sample(df):\n",
    "\n",
    "    sample_size = min(100000, len(df))\n",
    "    use_full = input(f\"Use full dataset ({len(df)} records) for model development? (y/n, default: n): \")\n",
    "    \n",
    "    if use_full.lower() == 'y':\n",
    "        print(f\"Using full dataset with {len(df)} records.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Using {sample_size} records for model development.\")\n",
    "        return df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "def get_problem_config(df):\n",
    "    # Show available targets\n",
    "    potential_targets = ['crime_category', 'crime_type', 'is_arrest', 'is_domestic', 'threat_level']\n",
    "    available_targets = [col for col in potential_targets if col in df.columns]\n",
    "    \n",
    "    print(\"\\nAvailable target variables:\")\n",
    "    for i, col in enumerate(available_targets, 1):\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{i}. {col} ({unique_vals} unique values)\")\n",
    "    \n",
    "    target_idx = 0\n",
    "    target_choice = input(f\"Choose target variable (1-{len(available_targets)}, default: 1): \")\n",
    "    try:\n",
    "        target_idx = int(target_choice) - 1 if target_choice else 0\n",
    "    except ValueError:\n",
    "        pass\n",
    "        \n",
    "    target_col = available_targets[target_idx]\n",
    "    \n",
    "    # Determine problem type\n",
    "    unique_vals = df[target_col].nunique()\n",
    "    class_problem = 'binary' if unique_vals == 2 else 'multiclass' if unique_vals < 100 else 'regression'\n",
    "\n",
    "    problem_choice = input(f\"Confirm problem type (binary/multiclass/regression, default: {class_problem}): \")\n",
    "    if problem_choice in ['binary', 'multiclass', 'regression']:\n",
    "        class_problem = problem_choice\n",
    "        \n",
    "    print(f\"Using {target_col} as target with {class_problem} problem type\")\n",
    "    return target_col, class_problem\n",
    "\n",
    "def save_final_results(performance, target_col, class_problem):\n",
    "\n",
    "    results_file = os.path.join(RESULTS_DIR, 'final_model_performance.json')\n",
    "    \n",
    "    results = {\n",
    "        'target_variable': target_col,\n",
    "        'problem_type': class_problem,\n",
    "        'model_performance': performance,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Final results saved to {results_file}\")\n",
    "\n",
    "def handle_class_imbalance_if_needed(datasets, class_problem):\n",
    "\n",
    "    if class_problem == 'regression':\n",
    "        return datasets\n",
    "        \n",
    "    y_train = datasets['y_train']\n",
    "    class_distribution = pd.Series(y_train).value_counts(normalize=True)\n",
    "    \n",
    "    imbalance_threshold = 0.2 \n",
    "    min_class_ratio = class_distribution.min()\n",
    "    \n",
    "    if min_class_ratio < imbalance_threshold:\n",
    "        print(f\"\\nDetected class imbalance (minimum class ratio: {min_class_ratio:.2%})\")\n",
    "        print(\"Current class distribution:\")\n",
    "        for cls, ratio in class_distribution.items():\n",
    "            print(f\"  Class {cls}: {ratio:.2%}\")\n",
    "            \n",
    "        # ask user if they want to handle class imbalance\n",
    "        handle_imbalance = input(\"\\nWould you like to handle class imbalance? (y/n, default: y): \")\n",
    "        \n",
    "        if handle_imbalance.lower() != 'n':\n",
    "            print(\"\\nAvailable methods:\")\n",
    "            print(\"1. SMOTE (over-sampling)\")\n",
    "            print(\"2. Random under-sampling\")\n",
    "            print(\"3. Combined (SMOTE + under-sampling)\")\n",
    "            \n",
    "            method_choice = input(\"Choose method (1-3, default: 1): \")\n",
    "            \n",
    "            method_map = {\n",
    "                '1': 'smote',\n",
    "                '2': 'undersampling',\n",
    "                '3': 'both'\n",
    "            }\n",
    "            \n",
    "            method = method_map.get(method_choice, 'smote')\n",
    "\n",
    "            X_resampled, y_resampled = handle_class_imbalance(\n",
    "                datasets['X_train'], \n",
    "                datasets['y_train'],\n",
    "                method=method\n",
    "            )\n",
    "\n",
    "            datasets['X_train'] = X_resampled\n",
    "            datasets['y_train'] = y_resampled\n",
    "            \n",
    "            print(\"\\nClass balance has been handled.\")\n",
    "            new_distribution = pd.Series(y_resampled).value_counts(normalize=True)\n",
    "            print(\"New class distribution:\")\n",
    "            for cls, ratio in new_distribution.items():\n",
    "                print(f\"  Class {cls}: {ratio:.2%}\")\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(datasets, model_type='random_forest', class_problem='multiclass'):\n",
    "\n",
    "    print(f\"\\n--- Optimizing Hyperparameters for {model_type} ---\")\n",
    "    \n",
    "    X_train, y_train = datasets['X_train'], datasets['y_train']\n",
    "    categorical_cols = datasets['categorical_cols']\n",
    "    numerical_cols = datasets['numerical_cols']\n",
    "\n",
    "    preprocessor = create_preprocessing_pipeline(categorical_cols, numerical_cols)\n",
    "    \n",
    "    param_grid = {}\n",
    "    \n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    elif model_type == 'gradient_boosting':\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Unsupported model type: {model_type}\")\n",
    "        return None\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    if class_problem in ['binary', 'multiclass'] and len(np.unique(y_train)) < 10:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv = 5\n",
    "    \n",
    "    # Grid Search \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid,\n",
    "        cv=cv, \n",
    "        scoring='accuracy' if class_problem in ['binary', 'multiclass'] else 'neg_mean_squared_error',\n",
    "        verbose=1, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print Best Parameters\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    save_model(best_model, f\"optimized_{model_type}\", {\n",
    "        'model_type': model_type,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'date_trained': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'cv_results': grid_search.cv_results_\n",
    "    }\n",
    "\n",
    "\n",
    "def optimize_if_requested(datasets, ml_results, class_problem):\n",
    "\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    for model_name, results in ml_results.items():\n",
    "        if class_problem in ['binary', 'multiclass']:\n",
    "            print(f\"{model_name}:\")\n",
    "            print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
    "            print(f\"  F1 Score: {results['f1_score']:.4f}\")\n",
    "        else:\n",
    "            print(f\"{model_name}:\")\n",
    "            print(f\"  RMSE: {results['rmse']:.4f}\")\n",
    "            print(f\"  R²: {results['r2']:.4f}\")\n",
    "    \n",
    "    optimize = input(\"\\nWould you like to optimize hyperparameters for any model? (y/n, default: n): \")\n",
    "    \n",
    "    if optimize.lower() == 'y':\n",
    "        print(\"\\nAvailable models for optimization:\")\n",
    "        print(\"1. Random Forest\")\n",
    "        print(\"2. Gradient Boosting\")\n",
    "        \n",
    "        model_choice = input(\"Choose model to optimize (1-2, default: 1): \")\n",
    "        \n",
    "        model_map = {\n",
    "            '1': 'random_forest',\n",
    "            '2': 'gradient_boosting'\n",
    "        }\n",
    "        \n",
    "        model_type = model_map.get(model_choice, 'random_forest')\n",
    "        \n",
    "        print(f\"\\nOptimizing {model_type}...\")\n",
    "        optimization_results = optimize_hyperparameters(\n",
    "            datasets,\n",
    "            model_type=model_type,\n",
    "            class_problem=class_problem\n",
    "        )\n",
    "        \n",
    "        if optimization_results:\n",
    "            ml_results[model_type] = {\n",
    "                'model': optimization_results['best_model'],\n",
    "                'accuracy': optimization_results['best_score'],\n",
    "                'parameters': optimization_results['best_params']\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{model_type} has been optimized.\")\n",
    "            print(f\"Best score: {optimization_results['best_score']:.4f}\")\n",
    "            print(\"Best parameters:\")\n",
    "            for param, value in optimization_results['best_params'].items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "    \n",
    "    return ml_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Train Traditional ML Models ------#\n",
    "\n",
    "def train_traditional_models(datasets, class_problem='multiclass'):\n",
    "    print(\"\\n--- Training Traditional ML Models ---\")\n",
    "    \n",
    "    X_train, y_train = datasets['X_train'], datasets['y_train']\n",
    "    X_test, y_test = datasets['X_test'], datasets['y_test']\n",
    "    categorical_cols = datasets['categorical_cols']\n",
    "    numerical_cols = datasets['numerical_cols']\n",
    "    \n",
    "    preprocessor = create_preprocessing_pipeline(categorical_cols, numerical_cols)\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    if class_problem in ['binary', 'multiclass']:\n",
    "        \n",
    "        # Random Forest\n",
    "        rf_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "        ])\n",
    "        models['random_forest'] = rf_model\n",
    "        \n",
    "        # Gradient Boosting\n",
    "        gb_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "        models['gradient_boosting'] = gb_model\n",
    "    \n",
    "    else:\n",
    "        print(\"Regression models are not implemented in this version.\")\n",
    "        return {}\n",
    "    \n",
    "    # Train and Evaluate Models\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if class_problem in ['binary', 'multiclass']:\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            try:\n",
    "                y_prob = model.predict_proba(X_test)\n",
    "                roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "            except:\n",
    "                roc_auc = None\n",
    "            \n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "            if roc_auc:\n",
    "                print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "            \n",
    "            save_model(model, f\"ml_{name}\", {\n",
    "                'model_type': name,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc\n",
    "                if roc_auc else None,\n",
    "                'date_trained': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            })\n",
    "\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "            # Save Evaluation Results\n",
    "            evaluation_results = {\n",
    "                'Model': name,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1 Score': f1,\n",
    "                'ROC AUC': roc_auc if roc_auc else None,\n",
    "                'Classification Report': report,\n",
    "                'Training Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            save_evaluation_results(evaluation_results, f\"ml_{name}\")\n",
    "            \n",
    "            # Save Results\n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc if roc_auc else None,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "        else:\n",
    "            print(\"Regression evaluation not implemented in this version.\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
    "        super(DenseNeuralNetwork, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        layers.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, nhead=4, num_layers=2, dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        # self.pos_encoder = PositionalEncoding(hidden_dim, dropout_rate)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=hidden_dim*4,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # [1, batch_size, hidden_dim]\n",
    "        x = self.transformer_encoder(x)  # [1, batch_size, hidden_dim]\n",
    "        \n",
    "        x = x[0]\n",
    "        x = self.output_layer(x)  # [batch_size, output_dim]\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_pytorch_model(model, X_train, y_train, X_val, y_val, \n",
    "                      model_name, class_problem='multiclass', batch_size=64, \n",
    "                      epochs=50, learning_rate=0.001):\n",
    "\n",
    "    model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "    \n",
    "    if class_problem == 'binary':\n",
    "        y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "        y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        output_activation = torch.sigmoid\n",
    "    elif class_problem == 'multiclass':\n",
    "        y_train_tensor = torch.LongTensor(y_train).to(device)\n",
    "        y_val_tensor = torch.LongTensor(y_val).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        output_activation = lambda x: torch.softmax(x, dim=1)\n",
    "    else:  # Regression\n",
    "        y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "        y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        output_activation = lambda x: x\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    \n",
    "    # Early Stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            if class_problem == 'binary':\n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Calculate Accuracy\n",
    "            if class_problem in ['binary', 'multiclass']:\n",
    "                if class_problem == 'binary':\n",
    "                    predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\n",
    "                else:\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                correct_train += (predicted == targets).sum().item()\n",
    "                total_train += targets.size(0)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if class_problem == 'binary':\n",
    "                    loss = criterion(outputs.squeeze(), targets)\n",
    "                else:\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                if class_problem in ['binary', 'multiclass']:\n",
    "                    if class_problem == 'binary':\n",
    "                        predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\n",
    "                    else:\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                    \n",
    "                    correct_val += (predicted == targets).sum().item()\n",
    "                    total_val += targets.size(0)\n",
    "    \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        if class_problem in ['binary', 'multiclass']:\n",
    "            train_acc = correct_train / total_train if total_train > 0 else 0\n",
    "            val_acc = correct_val / total_val if total_val > 0 else 0\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f} - \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f} - \"\n",
    "                  f\"Train Acc: {train_acc:.4f} - \"\n",
    "                  f\"Val Acc: {val_acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f} - \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Adjust Learning Rate\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    save_model(model, f\"pytorch_{model_name}\", {\n",
    "        'model_type': model_name,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'date_trained': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'input_dim': next(model.parameters()).shape[1] if len(list(model.parameters())) > 0 else None,\n",
    "        'output_dim': list(model.parameters())[-1].shape[0] if len(list(model.parameters())) > 0 else None,\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "\n",
    "def train_neural_networks(datasets, class_problem='multiclass'):\n",
    "\n",
    "    \n",
    "    X_train, y_train = datasets['X_train'], datasets['y_train']\n",
    "    X_test, y_test = datasets['X_test'], datasets['y_test']\n",
    "    categorical_cols = datasets['categorical_cols']\n",
    "    numerical_cols = datasets['numerical_cols']\n",
    "    \n",
    "    preprocessor = create_preprocessing_pipeline(categorical_cols, numerical_cols)\n",
    "    \n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    \n",
    "\n",
    "    joblib.dump(preprocessor, os.path.join(MODELS_DIR, \"preprocessor.pkl\"))\n",
    "    \n",
    "\n",
    "    if class_problem == 'binary':\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "        y_test_encoded = label_encoder.transform(y_test)\n",
    "        \n",
    "\n",
    "        n_classes = 1\n",
    "        output_activation = 'sigmoid'\n",
    "        \n",
    "    elif class_problem == 'multiclass':\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "        y_test_encoded = label_encoder.transform(y_test)\n",
    "        \n",
    "\n",
    "        n_classes = len(np.unique(y_train_encoded))\n",
    "        output_activation = 'softmax'\n",
    "        \n",
    "\n",
    "        joblib.dump(label_encoder, os.path.join(MODELS_DIR, \"label_encoder.pkl\"))\n",
    "        \n",
    "    else:\n",
    "\n",
    "        y_train_encoded = y_train\n",
    "        y_test_encoded = y_test\n",
    "        n_classes = 1\n",
    "        output_activation = 'linear'\n",
    "    \n",
    "\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "        X_train_processed, y_train_encoded, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    input_dim = X_train_processed.shape[1]\n",
    "    \n",
    "\n",
    "    nn_results = {}\n",
    "    \n",
    "    print(\"\\nTraining Dense Neural Network...\")\n",
    "    hidden_dims = [256, 128, 64]  \n",
    "    \n",
    "    dnn_model = DenseNeuralNetwork(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        output_dim=n_classes if class_problem == 'multiclass' else 1,\n",
    "        dropout_rate=0.3\n",
    "    )\n",
    "    \n",
    "    dnn_results = train_pytorch_model(\n",
    "        dnn_model, \n",
    "        X_train_final, y_train_final, \n",
    "        X_val, y_val, \n",
    "        'dnn',\n",
    "        class_problem\n",
    "    )\n",
    "    \n",
    "    dnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test_processed).to(device)\n",
    "        outputs = dnn_model(X_test_tensor)\n",
    "        \n",
    "        if class_problem == 'binary':\n",
    "            y_pred_dnn = (torch.sigmoid(outputs.squeeze()) > 0.5).cpu().numpy().astype(int)\n",
    "        elif class_problem == 'multiclass':\n",
    "            _, y_pred_dnn = torch.max(outputs, 1)\n",
    "            y_pred_dnn = y_pred_dnn.cpu().numpy()\n",
    "        else:\n",
    "            y_pred_dnn = outputs.cpu().numpy()\n",
    "    \n",
    "    # Evaluate DNN\n",
    "    if class_problem in ['binary', 'multiclass']:\n",
    "        accuracy = accuracy_score(y_test_encoded, y_pred_dnn)\n",
    "        precision = precision_score(y_test_encoded, y_pred_dnn, average='weighted')\n",
    "        recall = recall_score(y_test_encoded, y_pred_dnn, average='weighted')\n",
    "        f1 = f1_score(y_test_encoded, y_pred_dnn, average='weighted')\n",
    "        \n",
    "        print(f\"DNN - Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"DNN - Precision: {precision:.4f}\")\n",
    "        print(f\"DNN - Recall: {recall:.4f}\")\n",
    "        print(f\"DNN - F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        report = classification_report(y_test_encoded, y_pred_dnn, output_dict=True)\n",
    "        \n",
    "        evaluation_results = {\n",
    "            'Model': 'Dense Neural Network',\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Classification Report': report,\n",
    "            'Training History': {\n",
    "                'train_loss': dnn_results['history']['train_loss'],\n",
    "                'val_loss': dnn_results['history']['val_loss'],\n",
    "                'train_acc': dnn_results['history']['train_acc'],\n",
    "                'val_acc': dnn_results['history']['val_acc'],\n",
    "            },\n",
    "            'Training Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        save_evaluation_results(evaluation_results, \"pytorch_dnn\")\n",
    "        \n",
    "        nn_results['dnn'] = {\n",
    "            'model': dnn_model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'history': dnn_results['history']\n",
    "        }\n",
    "    else:\n",
    "        mae = mean_absolute_error(y_test_encoded, y_pred_dnn)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_encoded, y_pred_dnn))\n",
    "        r2 = r2_score(y_test_encoded, y_pred_dnn)\n",
    "        \n",
    "        print(f\"DNN - MAE: {mae:.4f}\")\n",
    "        print(f\"DNN - RMSE: {rmse:.4f}\")\n",
    "        print(f\"DNN - R²: {r2:.4f}\")\n",
    "        \n",
    "        nn_results['dnn'] = {\n",
    "            'model': dnn_model,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'history': dnn_results['history']\n",
    "        }\n",
    "    \n",
    "    print(\"\\nTraining Transformer Model...\")\n",
    "    hidden_dim = 128  \n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        output_dim=n_classes if class_problem == 'multiclass' else 1,\n",
    "        nhead=4, \n",
    "        num_layers=2  \n",
    "    )\n",
    "    \n",
    "    transformer_results = train_pytorch_model(\n",
    "        transformer_model, \n",
    "        X_train_final, y_train_final, \n",
    "        X_val, y_val, \n",
    "        'transformer',\n",
    "        class_problem\n",
    "    )\n",
    "    \n",
    "    # Best Model\n",
    "    transformer_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test_processed).to(device)\n",
    "        outputs = transformer_model(X_test_tensor)\n",
    "        \n",
    "        if class_problem == 'binary':\n",
    "            y_pred_transformer = (torch.sigmoid(outputs.squeeze()) > 0.5).cpu().numpy().astype(int)\n",
    "        elif class_problem == 'multiclass':\n",
    "            _, y_pred_transformer = torch.max(outputs, 1)\n",
    "            y_pred_transformer = y_pred_transformer.cpu().numpy()\n",
    "        else:\n",
    "            y_pred_transformer = outputs.cpu().numpy()\n",
    "    \n",
    "\n",
    "    if class_problem in ['binary', 'multiclass']:\n",
    "        accuracy = accuracy_score(y_test_encoded, y_pred_transformer)\n",
    "        precision = precision_score(y_test_encoded, y_pred_transformer, average='weighted')\n",
    "        recall = recall_score(y_test_encoded, y_pred_transformer, average='weighted')\n",
    "        f1 = f1_score(y_test_encoded, y_pred_transformer, average='weighted')\n",
    "        \n",
    "        print(f\"Transformer - Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Transformer - Precision: {precision:.4f}\")\n",
    "        print(f\"Transformer - Recall: {recall:.4f}\")\n",
    "        print(f\"Transformer - F1 Score: {f1:.4f}\")\n",
    "\n",
    "        report = classification_report(y_test_encoded, y_pred_transformer, output_dict=True)\n",
    "\n",
    "        evaluation_results = {\n",
    "            'Model': 'Transformer Model (PyTorch)',\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Classification Report': report,\n",
    "            'Training History': {\n",
    "                'train_loss': transformer_results['history']['train_loss'],\n",
    "                'val_loss': transformer_results['history']['val_loss'],\n",
    "                'train_acc': transformer_results['history']['train_acc'],\n",
    "                'val_acc': transformer_results['history']['val_acc'],\n",
    "            },\n",
    "            'Training Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        save_evaluation_results(evaluation_results, \"pytorch_transformer\")\n",
    "        \n",
    "        nn_results['transformer'] = {\n",
    "            'model': transformer_model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'history': transformer_results['history']\n",
    "        }\n",
    "    else:\n",
    "        mae = mean_absolute_error(y_test_encoded, y_pred_transformer)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_encoded, y_pred_transformer))\n",
    "        r2 = r2_score(y_test_encoded, y_pred_transformer)\n",
    "        \n",
    "        print(f\"Transformer - MAE: {mae:.4f}\")\n",
    "        print(f\"Transformer - RMSE: {rmse:.4f}\")\n",
    "        print(f\"Transformer - R²: {r2:.4f}\")\n",
    "        \n",
    "        nn_results['transformer'] = {\n",
    "            'model': transformer_model,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'history': transformer_results['history']\n",
    "        }\n",
    "    \n",
    "    return nn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize And Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(X_test, y_test, models, class_problem='multiclass'):\n",
    "    print(\"\\n--- Evaluating Model Performance ---\")\n",
    "    \n",
    "    # Load the preprocessor\n",
    "    try:\n",
    "        preprocessor = joblib.load(os.path.join(MODELS_DIR, \"preprocessor.pkl\"))\n",
    "        X_test_processed = preprocessor.transform(X_test)\n",
    "    except:\n",
    "        print(\"Error: Could not load preprocessor. Make sure it was saved during training.\")\n",
    "        return None\n",
    "    \n",
    "    performance = {}\n",
    "    \n",
    "    if class_problem in ['binary', 'multiclass']:\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        model_names = []\n",
    "\n",
    "        for name, model_info in models.items():\n",
    "            model = model_info['model']\n",
    "            \n",
    "            if isinstance(model, nn.Module):\n",
    "                # For Neural Network\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_test_tensor = torch.FloatTensor(X_test_processed).to(device)\n",
    "                    outputs = model(X_test_tensor)\n",
    "                    \n",
    "                    if class_problem == 'binary':\n",
    "                        y_pred = (torch.sigmoid(outputs.squeeze()) > 0.5).cpu().numpy().astype(int)\n",
    "                    else:\n",
    "                        _, y_pred = torch.max(outputs, 1)\n",
    "                        y_pred = y_pred.cpu().numpy()\n",
    "            else:\n",
    "                # For scikit-learn models\n",
    "                y_pred = model.predict(X_test)  # sklearn models handle preprocessing internally\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            accuracies.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "            model_names.append(name)\n",
    "\n",
    "            performance[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1\n",
    "            }\n",
    "            \n",
    "            print(f\"Model: {name}\")\n",
    "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"  Precision: {precision:.4f}\")\n",
    "            print(f\"  Recall: {recall:.4f}\")\n",
    "            print(f\"  F1 Score: {f1:.4f}\")\n",
    "            \n",
    "        best_model_idx = np.argmax(f1_scores)\n",
    "        best_model_name = model_names[best_model_idx]\n",
    "        \n",
    "        print(f\"\\nBest model based on F1 Score: {best_model_name}\")\n",
    "        print(f\"  Accuracy: {accuracies[best_model_idx]:.4f}\")\n",
    "        print(f\"  Precision: {precisions[best_model_idx]:.4f}\")\n",
    "        print(f\"  Recall: {recalls[best_model_idx]:.4f}\")\n",
    "        print(f\"  F1 Score: {f1_scores[best_model_idx]:.4f}\")\n",
    "    \n",
    "    # Regression\n",
    "    else:\n",
    "        maes = []\n",
    "        rmses = []\n",
    "        r2s = []\n",
    "        model_names = []\n",
    "\n",
    "        for name, model_info in models.items():\n",
    "            model = model_info['model']\n",
    "\n",
    "            if isinstance(model, nn.Module):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "                    y_pred = model(X_test_tensor).cpu().numpy()\n",
    "            else:\n",
    "\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            maes.append(mae)\n",
    "            rmses.append(rmse)\n",
    "            r2s.append(r2)\n",
    "            model_names.append(name)\n",
    "            \n",
    "            performance[name] = {\n",
    "                'mae': mae,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2\n",
    "            }\n",
    "            \n",
    "            print(f\"Model: {name}\")\n",
    "            print(f\"  MAE: {mae:.4f}\")\n",
    "            print(f\"  RMSE: {rmse:.4f}\")\n",
    "            print(f\"  R²: {r2:.4f}\")\n",
    "\n",
    "        best_model_idx = np.argmin(rmses)\n",
    "        best_model_name = model_names[best_model_idx]\n",
    "        \n",
    "        print(f\"\\nBest model based on RMSE: {best_model_name}\")\n",
    "        print(f\"  MAE: {maes[best_model_idx]:.4f}\")\n",
    "        print(f\"  RMSE: {rmses[best_model_idx]:.4f}\")\n",
    "        print(f\"  R²: {r2s[best_model_idx]:.4f}\")\n",
    "    \n",
    "    return performance\n",
    "\n",
    "def analyze_feature_importance(X_train, model, feature_names, model_name):\n",
    "\n",
    "    print(f\"\\n--- Analyzing Feature Importance for {model_name} ---\")\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        feature_importances = np.abs(model.coef_[0]) if len(model.coef_.shape) > 1 else np.abs(model.coef_)\n",
    "    else:\n",
    "        print(f\"Model {model_name} does not provide feature importance information\")\n",
    "        return\n",
    "    \n",
    "    if len(feature_names) != len(feature_importances):\n",
    "        print(f\"Length mismatch: {len(feature_names)} feature names vs {len(feature_importances)} importance values\")\n",
    "        if len(feature_names) > len(feature_importances):\n",
    "            feature_names = feature_names[:len(feature_importances)]\n",
    "        else:\n",
    "            feature_importances = feature_importances[:len(feature_names)]\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    \n",
    "    # Sort by Importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    importance_df.to_csv(os.path.join(RESULTS_DIR, f'{model_name}_feature_importance.csv'), index=False)\n",
    "\n",
    "    # Output Top 10 Important Features\n",
    "    top_features = importance_df.head(10)\n",
    "    print(\"Top 10 most important features:\")\n",
    "    for i, (feature, importance) in enumerate(zip(top_features['Feature'], top_features['Importance'])):\n",
    "        print(f\"  {i+1}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Use full dataset (100000 records) for model development? (y/n, default: n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100000 records for model development.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_feature_data('all_features.parquet')\n",
    "\n",
    "# Sample\n",
    "df_sample = get_data_sample(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available target variables:\n",
      "1. crime_category (6 unique values)\n",
      "2. crime_type (31 unique values)\n",
      "3. is_arrest (2 unique values)\n",
      "4. is_domestic (2 unique values)\n",
      "5. threat_level (3 unique values)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose target variable (1-5, default: 1):  4\n",
      "Confirm problem type (binary/multiclass/regression, default: binary):  binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using is_domestic as target with binary problem type\n",
      "Features: 66 total, 9 categorical, 32 numerical\n",
      "Training set: 70000 samples\n",
      "Test set: 30000 samples\n",
      "Target distribution in training set:\n",
      "  False: 84.83%\n",
      "  True: 15.17%\n"
     ]
    }
   ],
   "source": [
    "target_col, class_problem = get_problem_config(df_sample)\n",
    "\n",
    "# Drop features\n",
    "features_to_drop = [\n",
    "    'id', 'case_number', 'date', 'block', 'location', 'last_updated',\n",
    "    'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos', \n",
    "    'month_sin', 'month_cos'\n",
    "]\n",
    "\n",
    "datasets = prepare_datasets(\n",
    "    df_sample, target_col, test_size=0.3, \n",
    "    random_state=42, features_to_drop=features_to_drop\n",
    ")\n",
    "\n",
    "if datasets is None:\n",
    "    raise ValueError(\"Error preparing datasets\")\n",
    "    \n",
    "# datasets = handle_class_imbalance_if_needed(datasets, class_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Traditional ML Models ---\n",
      "\n",
      "Training random_forest...\n",
      "Accuracy: 0.9308\n",
      "Precision: 0.9277\n",
      "Recall: 0.9308\n",
      "F1 Score: 0.9274\n",
      "Model saved to models/ml_random_forest.pkl\n",
      "Model info saved to models/ml_random_forest_info.json\n",
      "Evaluation results saved to results/ml_random_forest_evaluation.txt\n",
      "\n",
      "Training gradient_boosting...\n",
      "Accuracy: 0.9317\n",
      "Precision: 0.9287\n",
      "Recall: 0.9317\n",
      "F1 Score: 0.9287\n",
      "Model saved to models/ml_gradient_boosting.pkl\n",
      "Model info saved to models/ml_gradient_boosting_info.json\n",
      "Evaluation results saved to results/ml_gradient_boosting_evaluation.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dense Neural Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 577.04it/s]\n",
      "Epoch 1/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2032.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.2315 - Val Loss: 0.1905 - Train Acc: 0.9130 - Val Acc: 0.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 645.39it/s]\n",
      "Epoch 2/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2083.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.1886 - Val Loss: 0.1836 - Train Acc: 0.9293 - Val Acc: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 674.05it/s]\n",
      "Epoch 3/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2342.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.1831 - Val Loss: 0.1830 - Train Acc: 0.9302 - Val Acc: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 683.43it/s]\n",
      "Epoch 4/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2390.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.1817 - Val Loss: 0.1833 - Train Acc: 0.9310 - Val Acc: 0.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 695.99it/s]\n",
      "Epoch 5/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2535.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.1800 - Val Loss: 0.1819 - Train Acc: 0.9316 - Val Acc: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 707.31it/s]\n",
      "Epoch 6/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2550.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.1773 - Val Loss: 0.1826 - Train Acc: 0.9317 - Val Acc: 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 648.32it/s]\n",
      "Epoch 7/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2571.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.1765 - Val Loss: 0.1838 - Train Acc: 0.9325 - Val Acc: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 708.17it/s]\n",
      "Epoch 8/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 2430.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.1740 - Val Loss: 0.1837 - Train Acc: 0.9323 - Val Acc: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|████████████████████| 875/875 [00:01<00:00, 616.88it/s]\n",
      "Epoch 9/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1958.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train Loss: 0.1731 - Val Loss: 0.1847 - Train Acc: 0.9325 - Val Acc: 0.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 735.01it/s]\n",
      "Epoch 10/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2557.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.1720 - Val Loss: 0.1843 - Train Acc: 0.9328 - Val Acc: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 693.27it/s]\n",
      "Epoch 11/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2504.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train Loss: 0.1707 - Val Loss: 0.1842 - Train Acc: 0.9338 - Val Acc: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 711.53it/s]\n",
      "Epoch 12/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2552.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train Loss: 0.1661 - Val Loss: 0.1839 - Train Acc: 0.9349 - Val Acc: 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 735.24it/s]\n",
      "Epoch 13/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2557.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train Loss: 0.1647 - Val Loss: 0.1847 - Train Acc: 0.9345 - Val Acc: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 700.94it/s]\n",
      "Epoch 14/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2524.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train Loss: 0.1636 - Val Loss: 0.1857 - Train Acc: 0.9349 - Val Acc: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|███████████████████| 875/875 [00:01<00:00, 704.46it/s]\n",
      "Epoch 15/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 2071.37it/s]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train Loss: 0.1623 - Val Loss: 0.1849 - Train Acc: 0.9350 - Val Acc: 0.9296\n",
      "Early stopping at epoch 15\n",
      "Model saved to models/pytorch_dnn.pkl\n",
      "Model info saved to models/pytorch_dnn_info.json\n",
      "DNN - Accuracy: 0.9315\n",
      "DNN - Precision: 0.9285\n",
      "DNN - Recall: 0.9315\n",
      "DNN - F1 Score: 0.9285\n",
      "Evaluation results saved to results/pytorch_dnn_evaluation.txt\n",
      "\n",
      "Training Transformer Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 241.33it/s]\n",
      "Epoch 1/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1148.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.2021 - Val Loss: 0.1903 - Train Acc: 0.9240 - Val Acc: 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 257.47it/s]\n",
      "Epoch 2/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1346.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Train Loss: 0.1857 - Val Loss: 0.1912 - Train Acc: 0.9296 - Val Acc: 0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 269.29it/s]\n",
      "Epoch 3/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1262.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Train Loss: 0.1822 - Val Loss: 0.1881 - Train Acc: 0.9299 - Val Acc: 0.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 285.95it/s]\n",
      "Epoch 4/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1359.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Train Loss: 0.1805 - Val Loss: 0.1882 - Train Acc: 0.9307 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 285.28it/s]\n",
      "Epoch 5/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1180.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Train Loss: 0.1807 - Val Loss: 0.1893 - Train Acc: 0.9303 - Val Acc: 0.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 286.78it/s]\n",
      "Epoch 6/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1260.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Train Loss: 0.1804 - Val Loss: 0.1867 - Train Acc: 0.9304 - Val Acc: 0.9290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 277.94it/s]\n",
      "Epoch 7/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1221.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Train Loss: 0.1790 - Val Loss: 0.1875 - Train Acc: 0.9309 - Val Acc: 0.9291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 283.81it/s]\n",
      "Epoch 8/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1369.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Train Loss: 0.1774 - Val Loss: 0.1886 - Train Acc: 0.9311 - Val Acc: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|████████████████████| 875/875 [00:03<00:00, 281.88it/s]\n",
      "Epoch 9/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 1400.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Train Loss: 0.1768 - Val Loss: 0.1964 - Train Acc: 0.9314 - Val Acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 283.08it/s]\n",
      "Epoch 10/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1159.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Train Loss: 0.1769 - Val Loss: 0.1860 - Train Acc: 0.9311 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|███████████████████| 875/875 [00:02<00:00, 291.97it/s]\n",
      "Epoch 11/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1389.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Train Loss: 0.1760 - Val Loss: 0.1897 - Train Acc: 0.9313 - Val Acc: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 281.11it/s]\n",
      "Epoch 12/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1282.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Train Loss: 0.1757 - Val Loss: 0.1901 - Train Acc: 0.9319 - Val Acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|███████████████████| 875/875 [00:04<00:00, 210.08it/s]\n",
      "Epoch 13/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1110.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Train Loss: 0.1748 - Val Loss: 0.1866 - Train Acc: 0.9323 - Val Acc: 0.9295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 251.69it/s]\n",
      "Epoch 14/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1228.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Train Loss: 0.1747 - Val Loss: 0.1873 - Train Acc: 0.9319 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 270.99it/s]\n",
      "Epoch 15/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1369.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Train Loss: 0.1745 - Val Loss: 0.1904 - Train Acc: 0.9321 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 265.69it/s]\n",
      "Epoch 16/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1006.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Train Loss: 0.1745 - Val Loss: 0.1845 - Train Acc: 0.9317 - Val Acc: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 250.87it/s]\n",
      "Epoch 17/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1142.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Train Loss: 0.1737 - Val Loss: 0.1862 - Train Acc: 0.9317 - Val Acc: 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 247.20it/s]\n",
      "Epoch 18/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1303.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Train Loss: 0.1737 - Val Loss: 0.1851 - Train Acc: 0.9322 - Val Acc: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 265.53it/s]\n",
      "Epoch 19/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1319.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Train Loss: 0.1733 - Val Loss: 0.1840 - Train Acc: 0.9324 - Val Acc: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 270.57it/s]\n",
      "Epoch 20/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1015.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Train Loss: 0.1727 - Val Loss: 0.1845 - Train Acc: 0.9311 - Val Acc: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 253.42it/s]\n",
      "Epoch 21/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1072.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Train Loss: 0.1732 - Val Loss: 0.1863 - Train Acc: 0.9322 - Val Acc: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 270.60it/s]\n",
      "Epoch 22/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1287.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Train Loss: 0.1721 - Val Loss: 0.1929 - Train Acc: 0.9324 - Val Acc: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 252.02it/s]\n",
      "Epoch 23/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1324.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Train Loss: 0.1725 - Val Loss: 0.1850 - Train Acc: 0.9328 - Val Acc: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 267.40it/s]\n",
      "Epoch 24/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1338.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Train Loss: 0.1719 - Val Loss: 0.1858 - Train Acc: 0.9323 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 258.35it/s]\n",
      "Epoch 25/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1028.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Train Loss: 0.1713 - Val Loss: 0.1857 - Train Acc: 0.9327 - Val Acc: 0.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 269.06it/s]\n",
      "Epoch 26/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1222.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Train Loss: 0.1687 - Val Loss: 0.1855 - Train Acc: 0.9338 - Val Acc: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 252.53it/s]\n",
      "Epoch 27/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1375.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Train Loss: 0.1674 - Val Loss: 0.1865 - Train Acc: 0.9342 - Val Acc: 0.9290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 250.19it/s]\n",
      "Epoch 28/50 [Val]: 100%|█████████████████████| 219/219 [00:00<00:00, 985.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Train Loss: 0.1672 - Val Loss: 0.1850 - Train Acc: 0.9337 - Val Acc: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|███████████████████| 875/875 [00:03<00:00, 241.24it/s]\n",
      "Epoch 29/50 [Val]: 100%|████████████████████| 219/219 [00:00<00:00, 1102.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Train Loss: 0.1668 - Val Loss: 0.1856 - Train Acc: 0.9338 - Val Acc: 0.9291\n",
      "Early stopping at epoch 29\n",
      "Model saved to models/pytorch_transformer.pkl\n",
      "Model info saved to models/pytorch_transformer_info.json\n",
      "Transformer - Accuracy: 0.9312\n",
      "Transformer - Precision: 0.9283\n",
      "Transformer - Recall: 0.9312\n",
      "Transformer - F1 Score: 0.9288\n",
      "Evaluation results saved to results/pytorch_transformer_evaluation.txt\n",
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Model: random_forest\n",
      "  Accuracy: 0.9308\n",
      "  Precision: 0.9277\n",
      "  Recall: 0.9308\n",
      "  F1 Score: 0.9274\n",
      "Model: gradient_boosting\n",
      "  Accuracy: 0.9317\n",
      "  Precision: 0.9287\n",
      "  Recall: 0.9317\n",
      "  F1 Score: 0.9287\n",
      "Model: dnn\n",
      "  Accuracy: 0.9315\n",
      "  Precision: 0.9285\n",
      "  Recall: 0.9315\n",
      "  F1 Score: 0.9285\n",
      "Model: transformer\n",
      "  Accuracy: 0.9312\n",
      "  Precision: 0.9283\n",
      "  Recall: 0.9312\n",
      "  F1 Score: 0.9288\n",
      "\n",
      "Best model based on F1 Score: transformer\n",
      "  Accuracy: 0.9312\n",
      "  Precision: 0.9283\n",
      "  Recall: 0.9312\n",
      "  F1 Score: 0.9288\n",
      "Final results saved to results/final_model_performance.json\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "ml_results = train_traditional_models(datasets, class_problem)\n",
    "nn_results = train_neural_networks(datasets, class_problem)\n",
    "\n",
    "# ml_results = optimize_if_requested(datasets, ml_results, class_problem)\n",
    "\n",
    "# Evaluate all models\n",
    "all_models = {**ml_results, **nn_results} if nn_results else ml_results\n",
    "\n",
    "performance = evaluate_model_performance(\n",
    "    datasets['X_test'], \n",
    "    datasets['y_test'],\n",
    "    all_models,\n",
    "    class_problem\n",
    ")\n",
    "\n",
    "# Save\n",
    "save_final_results(performance, target_col, class_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
